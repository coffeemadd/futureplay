{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nTrend Analysis\\n1. Transform description of companies into clean word tokens. (bigram \\xed\\x8f\\xac\\xed\\x95\\xa8)\\n2. Run word2vec\\n3. Given a keyword, get related words, and plot distribution of companies.\\n4. Automatically extract important keywords\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Trend Analysis\n",
    "1. Transform description of companies into clean word tokens. (bigram 포함)\n",
    "2. Run word2vec\n",
    "3. Given a keyword, get related words, and plot distribution of companies.\n",
    "4. Automatically extract important keywords\n",
    "Approach 4-1 word network \n",
    "Approach 4-2 temporal analysis\n",
    "Approach 4-3 topic model\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import gensim\n",
    "import pickle\n",
    "from datetime import datetime\n",
    "from matplotlib import pyplot as plt\n",
    "import networkx as nx\n",
    "import operator\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load data\n",
    "data_folder = '../data/csv_export/'\n",
    "util_folder = '../util/'\n",
    "df_organizations = pd.read_csv(data_folder + 'organizations.csv'.format(data_folder), dtype={'first_funding_on': str, 'last_funding_on':str})\n",
    "df_description = pd.read_csv(data_folder + 'organization_descriptions.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 1. Transform description of companies into clean word tokens. (bigram 포함)\n",
    "# A. 문장 전처리 Helper function to clean string into list of word tokens\n",
    "\n",
    "# input: string\n",
    "# output: list of clean word tokens\n",
    "def clean(string):\n",
    "    # remove non-alphabet\n",
    "    string = re.sub(\"[^a-zA-Z]\", \" \", string)\n",
    "    # lower case\n",
    "    string = string.lower()\n",
    "    # remove word with length 1\n",
    "    string = [word for word in string.split() if len(word) > 1]    \n",
    "    return string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading descriptions\n",
      "0 / 346275\n",
      "50000 / 346275\n",
      "nan\n",
      "nan\n",
      "100000 / 346275\n",
      "150000 / 346275\n",
      "200000 / 346275\n",
      "250000 / 346275\n",
      "300000 / 346275\n",
      "nan\n",
      "learning bigrams\n",
      "getting bigram sentences\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/joonheekim/Projects/futureplay/venv/lib/python2.7/site-packages/gensim/models/phrases.py:274: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n"
     ]
    }
   ],
   "source": [
    "# 1. Transform description of companies into clean word tokens. (bigram 포함)\n",
    "# B. create corpus, and learn bigrams\n",
    "\n",
    "print('reading descriptions')\n",
    "sentences = []\n",
    "# company description is in organization_descriptions.csv file\n",
    "for index, row in df_description.iterrows():\n",
    "    try:\n",
    "        token_list = clean(row['description'])\n",
    "    except TypeError:\n",
    "        print(row['description'])\n",
    "    sentences.append(token_list)\n",
    "    if index % 50000 == 0: print('{} / {}'.format(index, df_description.shape[0]))\n",
    "\n",
    "# use gensim to learn bigrams from data\n",
    "# they contain important information such as [deep_learning, artificial_intelligence]\n",
    "print('learning bigrams')\n",
    "bigram_transformer = gensim.models.Phrases(sentences)\n",
    "print('getting bigram sentences')\n",
    "bigram_sentences = bigram_transformer[sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating dictionary of 346275 documents\n",
      "before: Dictionary(434521 unique tokens: [u'must_pass', u'sowela', u'mdbg', u'soscharger', u'spiderg']...)\n",
      "after: Dictionary(57082 unique tokens: [u'must_pass', u'cleveland_oh', u'clinical_laboratory', u'localizes', u'standardized_tests']...)\n"
     ]
    }
   ],
   "source": [
    "# 1. Transform description of companies into clean word tokens. (bigram 포함)\n",
    "# C. dictionary 를 만들고 저장한다\n",
    "\n",
    "# create dictionary\n",
    "print('creating dictionary of {} documents'.format(len(sentences)))\n",
    "dictionary = gensim.corpora.dictionary.Dictionary()\n",
    "dictionary.add_documents(bigram_sentences)\n",
    "\n",
    "# filter extreme (words too frequent, and too infrequent)\n",
    "print('before: {}'.format(dictionary))\n",
    "dictionary.filter_extremes(no_above=0.1, no_below=10)\n",
    "print('after: {}'.format(dictionary))\n",
    "\n",
    "# save dictionary\n",
    "dictionary.save(util_folder + 'dictionary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 / 346275\n",
      "50000 / 346275\n",
      "nan\n",
      "nan\n",
      "100000 / 346275\n",
      "150000 / 346275\n",
      "200000 / 346275\n",
      "250000 / 346275\n",
      "300000 / 346275\n",
      "nan\n"
     ]
    }
   ],
   "source": [
    "# 1. Transform description of companies into clean word tokens. (bigram 포함)\n",
    "# D. 단어와 회사의 매핑을 만든다. 추후에 단어가 주어졌을때 관련된 회사를 찾을때 사용된다 (반대 경우도)\n",
    "\n",
    "word2company = {}\n",
    "company2word = {}\n",
    "for index, row in df_description.iterrows():\n",
    "    company = row[0]\n",
    "    if index % 50000 == 0: print('{} / {}'.format(index, df_description.shape[0]))\n",
    "\n",
    "    # 회사의 설명에 쓰인 문장을 갖고 온다\n",
    "    try:\n",
    "        sentence = clean(row['description'])\n",
    "    except TypeError:\n",
    "        print(row['description'])\n",
    "\n",
    "    # bigram 도 포함하게 변환\n",
    "    bigram_sentence = bigram_transformer[sentence]\n",
    "    \n",
    "    # keep track of company <-> word mapping\n",
    "    company2word[company] = []\n",
    "    for word in bigram_sentence:\n",
    "        if word not in word2company: word2company[word] = []\n",
    "        word2company[word].append(company)\n",
    "        company2word[company].append(word)\n",
    "\n",
    "# 겹치는 경우 뺀다\n",
    "for word, _list in word2company.items():\n",
    "    _list = list(set(_list))\n",
    "    word2company[word] = _list\n",
    "for company, _list in company2word.items():\n",
    "    _list = list(set(_list))\n",
    "    company2word[company] = _list\n",
    "    \n",
    "f = open(util_folder + 'word2company.pickle', 'w')\n",
    "pickle.dump(word2company, f)\n",
    "f.close()\n",
    "\n",
    "f = open(util_folder + 'company2word.pickle', 'w')\n",
    "pickle.dump(company2word, f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 346275\n",
      "50000 346275\n",
      "100000 346275\n",
      "150000 346275\n",
      "200000 346275\n",
      "250000 346275\n",
      "300000 346275\n"
     ]
    }
   ],
   "source": [
    "# 2. Run word2vec\n",
    "# A. run word2vec to learn word similarity\n",
    "\n",
    "# transform corpus to include bigrams\n",
    "bigram_sentences_for_word2vec = []\n",
    "count = 0\n",
    "for sentence in sentences:\n",
    "    if count % 50000 == 0: print count, len(sentences)\n",
    "    bigram_sentence = bigram_transformer[sentence]\n",
    "    bigram_sentences_for_word2vec.append(bigram_sentence)\n",
    "    count += 1\n",
    "\n",
    "# run word2vec and save result\n",
    "model = gensim.models.word2vec.Word2Vec(bigram_sentences_for_word2vec, iter = 30)\n",
    "model.save(util_folder + 'word2vec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 3. Given a keyword, get related words, and plot distribution of companies.\n",
    "# A.\n",
    "# input:\n",
    "# words = keyword (str) or keywords (list)\n",
    "# condition = founded_on (str) or first_funding_on (str) (founed_on 일 경우 데이터가 정확하지 않음. 1월과 1일에 몰려 있음)\n",
    "# expand (bool) = 키워드를 확장할 것인가\n",
    "\n",
    "def plot_trend(words, condition = 'founded_on', expand = False):\n",
    "    # load required dataset\n",
    "    if 'word2company' not in globals():\n",
    "        print('loading word2company')\n",
    "        global word2company\n",
    "        word2company = pickle.load(open(util_folder + 'word2company.pickle'))\n",
    "    if 'model' not in globals():\n",
    "        print('loading word2vec model')\n",
    "        global model\n",
    "        model = gensim.models.word2vec.Word2Vec.load(util_folder + 'word2vec')\n",
    "        \n",
    "    # expand word set if necessary\n",
    "    # train 된 word2vec 을 사용하여 관련도가 높은 단어들을 포함한다\n",
    "    final_words = []\n",
    "    if type(words) == str:\n",
    "        words = [words]\n",
    "    for word in words:\n",
    "        if ' ' in word:\n",
    "            word = word.replace(' ', '_')\n",
    "        if expand:\n",
    "            _words = model.most_similar(word)\n",
    "            _words = [str(_word) for _word, sim in _words]\n",
    "            final_words.extend(_words)\n",
    "        final_words.append(word)\n",
    "    final_words = list(set(final_words))\n",
    "\n",
    "    # choose companies that have relevant words\n",
    "    companies = []\n",
    "    for word in final_words:\n",
    "        _companies = word2company.get(word, [])\n",
    "        companies.extend(_companies)\n",
    "    companies = list(set(companies))\n",
    "\n",
    "    # 회사를 시기 별로 정리한다\n",
    "    dates = df_organizations[df_organizations['uuid'].isin(companies)][condition].values\n",
    "    new_dates = []\n",
    "    for date in dates:\n",
    "        try:\n",
    "            date = datetime.strptime(date, '%Y-%m-%d')\n",
    "            new_dates.append(date)\n",
    "        except Exception as e:\n",
    "            pass\n",
    "    print('target word: {}, unique companies: {}, out of which {} meet condition,'.format(final_words, len(companies), len(new_dates)))\n",
    "    df = pd.DataFrame({'dates':new_dates})\n",
    "    df.dates = pd.to_datetime(df.dates)\n",
    "\n",
    "    # 1년 단위로 plot 한다\n",
    "#     df.groupby([df[\"dates\"].dt.year]).count().plot(kind='bar', figsize = (8, 4))\n",
    "    # 3개월 단위로 plot 한다\n",
    "    df.groupby([df[\"dates\"].dt.year, df[\"dates\"].dt.quarter]).count().plot(kind='bar', figsize = (15, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target word: ['neural_network', 'computer_vision', 'neural_networks', 'machine_learning', 'artificial_intelligence', 'deep_learning'], unique companies: 2991, out of which 1510 meet condition,\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA3AAAAEuCAYAAADP8fB5AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYbXIifiNQjwAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x191eb3e50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 3. Given a keyword, get related words, and plot distribution of companies.\n",
    "# B. usage examples\n",
    "\n",
    "# plot_trend('deep learning')\n",
    "# plot_trend(['deep learning'], condition = 'founded_on', expand = False)\n",
    "plot_trend(['deep learning', 'neural network', 'computer vision', 'neural networks', 'machine learning', 'artificial intelligence'], condition = 'first_funding_on', expand = False)\n",
    "# plot_trend('fintech', condition = 'first_funding_on', expand = False)\n",
    "# plot_trend('artificial intelligence')\n",
    "# plot_trend('artificial intelligence', condition = 'first_funding_on', expand = True)\n",
    "# plot_trend('connected car', condition = 'first_funding_on', expand = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 346275\n",
      "10000 346275\n",
      "20000 346275\n",
      "30000 346275\n",
      "40000 346275\n",
      "50000 346275\n",
      "60000 346275\n",
      "70000 346275\n",
      "80000 346275\n",
      "90000 346275\n",
      "100000 346275\n",
      "110000 346275\n",
      "120000 346275\n",
      "130000 346275\n",
      "140000 346275\n",
      "150000 346275\n",
      "160000 346275\n",
      "170000 346275\n",
      "180000 346275\n",
      "190000 346275\n",
      "200000 346275\n",
      "210000 346275\n",
      "220000 346275\n",
      "230000 346275\n",
      "240000 346275\n",
      "250000 346275\n",
      "260000 346275\n",
      "270000 346275\n",
      "280000 346275\n",
      "290000 346275\n",
      "300000 346275\n",
      "310000 346275\n",
      "320000 346275\n",
      "330000 346275\n",
      "340000 346275\n"
     ]
    }
   ],
   "source": [
    "# 4. Automatically extract important keywords\n",
    "# Approach 1: build word network, run pagerank to get words with high centrality\n",
    "\n",
    "# get data\n",
    "bigram_sentences_for_wordrank = []\n",
    "count = 0\n",
    "df = {}\n",
    "for sentence in sentences:\n",
    "    if count % 50000 == 0: print count, len(sentences)\n",
    "    bigram_sentence = bigram_transformer[sentence]\n",
    "    word_list = list(set(bigram_sentence))\n",
    "    for word in word_list:\n",
    "        df[word] = df.get(word, 0) + 1\n",
    "    bigram_sentences_for_wordrank.append(bigram_sentence)\n",
    "    count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50 0.1\n",
      "20 0.1\n"
     ]
    }
   ],
   "source": [
    "# 4. Automatically extract important keywords\n",
    "# Approach 1: build word network, run pagerank to get words with high centrality\n",
    "\n",
    "# get words to include in the network\n",
    "no_below = 50\n",
    "no_above = 0.1\n",
    "for no_below in [50, 20]:\n",
    "    print no_below, no_above\n",
    "    good_words = {}\n",
    "    for word, count in df.items():\n",
    "        if count > no_below and count < len(sentences) * no_above:\n",
    "            good_words[word] = None\n",
    "    f = open(util_folder + '{}_{}.pickles'.format(no_below, no_above), 'w')\n",
    "    pickle.dump(good_words, f)\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19013\n",
      "0 346275\n",
      "1000 346275\n",
      "2000 346275\n",
      "3000 346275\n",
      "4000 346275\n",
      "5000 346275\n",
      "6000 346275\n",
      "7000 346275\n",
      "8000 346275\n",
      "9000 346275\n",
      "10000 346275\n",
      "11000 346275\n",
      "12000 346275\n",
      "13000 346275\n",
      "14000 346275\n",
      "15000 346275\n",
      "16000 346275\n",
      "17000 346275\n",
      "18000 346275\n",
      "19000 346275\n",
      "20000 346275\n",
      "21000 346275\n",
      "22000 346275\n",
      "23000 346275\n",
      "24000 346275\n",
      "25000 346275\n",
      "26000 346275\n",
      "27000 346275\n",
      "28000 346275\n",
      "29000 346275\n",
      "30000 346275\n",
      "31000 346275\n",
      "32000 346275\n",
      "33000 346275\n",
      "34000 346275\n",
      "35000 346275\n",
      "36000 346275\n",
      "37000 346275\n",
      "38000 346275\n",
      "39000 346275\n",
      "40000 346275\n",
      "41000 346275\n",
      "42000 346275\n",
      "43000 346275\n",
      "44000 346275\n",
      "45000 346275\n",
      "46000 346275\n",
      "47000 346275\n",
      "48000 346275\n",
      "49000 346275\n",
      "50000 346275\n",
      "51000 346275\n",
      "52000 346275\n",
      "53000 346275\n",
      "54000 346275\n",
      "55000 346275\n",
      "56000 346275\n",
      "57000 346275\n",
      "58000 346275\n",
      "59000 346275\n",
      "60000 346275\n",
      "61000 346275\n",
      "62000 346275\n",
      "63000 346275\n",
      "64000 346275\n",
      "65000 346275\n",
      "66000 346275\n",
      "67000 346275\n",
      "68000 346275\n",
      "69000 346275\n",
      "70000 346275\n",
      "71000 346275\n",
      "72000 346275\n",
      "73000 346275\n",
      "74000 346275\n",
      "75000 346275\n",
      "76000 346275\n",
      "77000 346275\n",
      "78000 346275\n",
      "79000 346275\n",
      "80000 346275\n",
      "81000 346275\n",
      "82000 346275\n",
      "83000 346275\n",
      "84000 346275\n",
      "85000 346275\n",
      "86000 346275\n",
      "87000 346275\n",
      "88000 346275\n",
      "89000 346275\n",
      "90000 346275\n",
      "91000 346275\n",
      "92000 346275\n",
      "93000 346275\n",
      "94000 346275\n",
      "95000 346275\n",
      "96000 346275\n",
      "97000 346275\n",
      "98000 346275\n",
      "99000 346275\n",
      "100000 346275\n",
      "101000 346275\n",
      "102000 346275\n",
      "103000 346275\n",
      "104000 346275\n",
      "105000 346275\n",
      "106000 346275\n",
      "107000 346275\n",
      "108000 346275\n",
      "109000 346275\n",
      "110000 346275\n",
      "111000 346275\n",
      "112000 346275\n",
      "113000 346275\n",
      "114000 346275\n",
      "115000 346275\n",
      "116000 346275\n",
      "117000 346275\n",
      "118000 346275\n",
      "119000 346275\n",
      "120000 346275\n",
      "121000 346275\n",
      "122000 346275\n",
      "123000 346275\n",
      "124000 346275\n",
      "125000 346275\n",
      "126000 346275\n",
      "127000 346275\n",
      "128000 346275\n",
      "129000 346275\n",
      "130000 346275\n",
      "131000 346275\n",
      "132000 346275\n",
      "133000 346275\n",
      "134000 346275\n",
      "135000 346275\n",
      "136000 346275\n",
      "137000 346275\n",
      "138000 346275\n",
      "139000 346275\n",
      "140000 346275\n",
      "141000 346275\n",
      "142000 346275\n",
      "143000 346275\n",
      "144000 346275\n",
      "145000 346275\n",
      "146000 346275\n",
      "147000 346275\n",
      "148000 346275\n",
      "149000 346275\n",
      "150000 346275\n",
      "151000 346275\n",
      "152000 346275\n",
      "153000 346275\n",
      "154000 346275\n",
      "155000 346275\n",
      "156000 346275\n",
      "157000 346275\n",
      "158000 346275\n",
      "159000 346275\n",
      "160000 346275\n",
      "161000 346275\n",
      "162000 346275\n",
      "163000 346275\n",
      "164000 346275\n",
      "165000 346275\n",
      "166000 346275\n",
      "167000 346275\n",
      "168000 346275\n",
      "169000 346275\n",
      "170000 346275\n",
      "171000 346275\n",
      "172000 346275\n",
      "173000 346275\n",
      "174000 346275\n",
      "175000 346275\n",
      "176000 346275\n",
      "177000 346275\n",
      "178000 346275\n",
      "179000 346275\n",
      "180000 346275\n",
      "181000 346275\n",
      "182000 346275\n",
      "183000 346275\n",
      "184000 346275\n",
      "185000 346275\n",
      "186000 346275\n",
      "187000 346275\n",
      "188000 346275\n",
      "189000 346275\n",
      "190000 346275\n",
      "191000 346275\n",
      "192000 346275\n",
      "193000 346275\n",
      "194000 346275\n",
      "195000 346275\n",
      "196000 346275\n",
      "197000 346275\n",
      "198000 346275\n",
      "199000 346275\n",
      "200000 346275\n",
      "201000 346275\n",
      "202000 346275\n",
      "203000 346275\n",
      "204000 346275\n",
      "205000 346275\n",
      "206000 346275\n",
      "207000 346275\n",
      "208000 346275\n",
      "209000 346275\n",
      "210000 346275\n",
      "211000 346275\n",
      "212000 346275\n",
      "213000 346275\n",
      "214000 346275\n",
      "215000 346275\n",
      "216000 346275\n",
      "217000 346275\n",
      "218000 346275\n",
      "219000 346275\n",
      "220000 346275\n",
      "221000 346275\n",
      "222000 346275\n",
      "223000 346275\n",
      "224000 346275\n",
      "225000 346275\n",
      "226000 346275\n",
      "227000 346275\n",
      "228000 346275\n",
      "229000 346275\n",
      "230000 346275\n",
      "231000 346275\n",
      "232000 346275\n",
      "233000 346275\n",
      "234000 346275\n",
      "235000 346275\n",
      "236000 346275\n",
      "237000 346275\n",
      "238000 346275\n",
      "239000 346275\n",
      "240000 346275\n",
      "241000 346275\n",
      "242000 346275\n",
      "243000 346275\n",
      "244000 346275\n",
      "245000 346275\n",
      "246000 346275\n",
      "247000 346275\n",
      "248000 346275\n",
      "249000 346275\n",
      "250000 346275\n",
      "251000 346275\n",
      "252000 346275\n",
      "253000 346275\n",
      "254000 346275\n",
      "255000 346275\n",
      "256000 346275\n",
      "257000 346275\n",
      "258000 346275\n",
      "259000 346275\n",
      "260000 346275\n",
      "261000 346275\n",
      "262000 346275\n",
      "263000 346275\n",
      "264000 346275\n",
      "265000 346275\n",
      "266000 346275\n",
      "267000 346275\n",
      "268000 346275\n",
      "269000 346275\n",
      "270000 346275\n",
      "271000 346275\n",
      "272000 346275\n",
      "273000 346275\n",
      "274000 346275\n",
      "275000 346275\n",
      "276000 346275\n",
      "277000 346275\n",
      "278000 346275\n",
      "279000 346275\n",
      "280000 346275\n",
      "281000 346275\n",
      "282000 346275\n",
      "283000 346275\n",
      "284000 346275\n",
      "285000 346275\n",
      "286000 346275\n",
      "287000 346275\n",
      "288000 346275\n",
      "289000 346275\n",
      "290000 346275\n",
      "291000 346275\n",
      "292000 346275\n",
      "293000 346275\n",
      "294000 346275\n",
      "295000 346275\n",
      "296000 346275\n",
      "297000 346275\n",
      "298000 346275\n",
      "299000 346275\n",
      "300000 346275\n",
      "301000 346275\n",
      "302000 346275\n",
      "303000 346275\n",
      "304000 346275\n",
      "305000 346275\n",
      "306000 346275\n",
      "307000 346275\n",
      "308000 346275\n",
      "309000 346275\n",
      "310000 346275\n",
      "311000 346275\n",
      "312000 346275\n",
      "313000 346275\n",
      "314000 346275\n"
     ]
    }
   ],
   "source": [
    "# 4. Automatically extract important keywords\n",
    "# Approach 1: build word network, run pagerank to get words with high centrality\n",
    "\n",
    "# build network\n",
    "# currently it takes too long + takes too much memory 20gb+\n",
    "\n",
    "no_below = 50\n",
    "no_above = 0.1\n",
    "good_words = pickle.load(open(util_folder + '{}_{}.pickles'.format(no_below, no_above)))\n",
    "print(len(good_words))\n",
    "g = nx.Graph()\n",
    "count = 0\n",
    "for sentence in bigram_sentences_for_wordrank:\n",
    "    if count % 1000 == 0: print count, len(sentences)\n",
    "    count += 1\n",
    "    for i, word1 in enumerate(sentence):\n",
    "        for j, word2 in enumerate(sentence):\n",
    "            if i == j: continue\n",
    "            if word1 in good_words and word2 in good_words:\n",
    "                g.add_edge(word1, word2)\n",
    "\n",
    "central = nx.degree_centrality(g)\n",
    "central = sorted(central.items(), key=operator.itemgetter(1))\n",
    "central.reverse()\n",
    "words = [word for word, value in central]\n",
    "print words[:100]\n",
    "f = open(util_folder + 'keywords_network.pickle')\n",
    "pickle.dump(central, f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 4. Automatically extract important keywords\n",
    "# Approach 2: 기간에 따라 급격히 달라지는 단어의 흐름으로 키워드 찾아내기\n",
    "# 2-1. keyword1: 특정 기간 전후로 사용 비율이 급격히 높은 단어들 보기\n",
    "# 2-2. keyword2: 특저 기간 내에 사용 비율이 다른 때 보다 급격히 높은 단어들 보기\n",
    "\n",
    "WORD_MIN = 10 # minimum number of occurrences to be considered as a keyword\n",
    "def keyword1(before_after):\n",
    "    # load required dataset\n",
    "    if 'word2company' not in globals():\n",
    "        print('loading word2company')\n",
    "        global word2company\n",
    "        word2company = pickle.load(open(util_folder + 'word2company.pickle'))\n",
    "    if 'company2word' not in globals():\n",
    "        print('loading company2word')\n",
    "        global company2word\n",
    "        company2word = pickle.load(open(util_folder + 'company2word.pickle'))\n",
    "    if 'model' not in globals():\n",
    "        print('loading word2vec model')\n",
    "        global model\n",
    "        model = gensim.models.word2vec.Word2Vec.load(util_folder + 'word2vec')\n",
    "        \n",
    "    # 기간 전의 회사들, 기간 후의 회사들\n",
    "    companies_before = df_organizations[df_organizations['founded_on'] < before_after]\n",
    "    companies_after = df_organizations[df_organizations['founded_on'] >= before_after]\n",
    "    print('Extracting keywords from startups after {}'.format(before_after))\n",
    "    print('before: {} after: {}'.format(companies_before.shape[0], companies_after.shape[0]))\n",
    "    \n",
    "    # 기간 전의 회사들, 기간 후의 회사들로부터 각 단어의 document frequency (DF) 를 측정한다.\n",
    "    df_before = {}\n",
    "    df_after = {}\n",
    "    for company in companies_before['uuid'].values:\n",
    "        words = company2word.get(company, [])\n",
    "        words = list(set(words))\n",
    "        for word in words:\n",
    "            df_before[word] = df_before.get(word, 0) + 1\n",
    "    for company in companies_after['uuid'].values:\n",
    "        words = company2word.get(company, [])\n",
    "        words = list(set(words))\n",
    "        for word in words:\n",
    "            df_after[word] = df_after.get(word, 0) + 1\n",
    "            \n",
    "    # 각 단어의 사용 비율을 측정한다 (전체 문서에서 각 단어가 사용될 확률)\n",
    "    ratio_dict = {}\n",
    "    for word, count in df_after.items():\n",
    "        if count >= WORD_MIN:\n",
    "            # smoothing factor 포함\n",
    "            smooth = 0.00001\n",
    "            ratio_before = df_before.get(word, 0) / float(len(companies_before['uuid'].values)) + smooth\n",
    "            ratio_after = df_after.get(word, 0) / float(len(companies_after['uuid'].values)) + smooth\n",
    "            ratio_dict[word] = ratio_after / ratio_before\n",
    "\n",
    "    # 결과를 sorting 해서 리스트의 형태로\n",
    "    # [(keyword1, score1), (keyword2, score2), ...]\n",
    "    ratio_dict = sorted(ratio_dict.items(), key=operator.itemgetter(1))\n",
    "    ratio_dict.reverse()\n",
    "    print ratio_dict[:50]\n",
    "    f = open(util_folder + 'keywords1_' + before_after + '_ratio.pickle', 'w')\n",
    "    pickle.dump(ratio_dict, f)\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Automatically extract important keywords\n",
    "# Approach 2-1: 사용 예제\n",
    "\n",
    "for year in range(2000, 2017):\n",
    "    keyword1('{}-01-01'.format(year))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 4. Automatically extract important keywords\n",
    "# Approach 2: 기간에 따라 급격히 달라지는 단어의 흐름으로 키워드 찾아내기\n",
    "# 2-1. keyword1: 특정 기간 전후로 사용 비율이 급격히 높은 단어들 보기\n",
    "# 2-2. keyword2: 특저 기간 내에 사용 비율이 다른 때 보다 급격히 높은 단어들 보기\n",
    "\n",
    "WORD_MIN = 10 # minimum number of occurrences to be considered as a keyword\n",
    "# word2company = pickle.load(open(util_folder + 'word2company.pickle'))\n",
    "# company2word = pickle.load(open(util_folder + 'company2word.pickle'))\n",
    "def keyword2(after, before):\n",
    "    # load required dataset\n",
    "    if 'word2company' not in globals():\n",
    "        print('loading word2company')\n",
    "        global word2company\n",
    "        word2company = pickle.load(open(util_folder + 'word2company.pickle'))\n",
    "    if 'company2word' not in globals():\n",
    "        print('loading company2word')\n",
    "        global company2word\n",
    "        company2word = pickle.load(open(util_folder + 'company2word.pickle'))\n",
    "    if 'model' not in globals():\n",
    "        print('loading word2vec model')\n",
    "        global model\n",
    "        model = gensim.models.word2vec.Word2Vec.load(util_folder + 'word2vec')\n",
    "        \n",
    "    # 기간 사이에 속하는 회사들과 그렇지 않은 회사들 분류\n",
    "    companies_yes = df_organizations[df_organizations['founded_on'] < before]\n",
    "    companies_yes = companies_yes[companies_yes['founded_on'] >= after]\n",
    "    companies_no = df_organizations[~df_organizations['uuid'].isin(companies_yes['uuid'].values)]\n",
    "    print('Extracting keywords from startups after {} and no {}'.format(after, before))\n",
    "    print('no: {} yes: {}'.format(companies_no.shape[0], companies_yes.shape[0]))\n",
    "\n",
    "    # 각 단어의 document frequency (DF) 측정\n",
    "    df_no = {}\n",
    "    df_yes = {}\n",
    "    for company in companies_no['uuid'].values:\n",
    "        words = company2word.get(company, [])\n",
    "        words = list(set(words))\n",
    "        for word in words:\n",
    "            df_no[word] = df_no.get(word, 0) + 1\n",
    "    for company in companies_yes['uuid'].values:\n",
    "        words = company2word.get(company, [])\n",
    "        words = list(set(words))\n",
    "        for word in words:\n",
    "            df_yes[word] = df_yes.get(word, 0) + 1\n",
    "            \n",
    "    # 각 단어의 사용 비율 측정\n",
    "    ratio_dict = {}\n",
    "    for word, count in df_yes.items():\n",
    "        if count >= WORD_MIN:\n",
    "            smoothing = 0.00000001\n",
    "            ratio_no = df_no.get(word, 0) / float(len(companies_no['uuid'].values)) + smoothing\n",
    "            ratio_yes = df_yes.get(word, 0) / float(len(companies_yes['uuid'].values)) + smoothing\n",
    "#             print word, ratio_no, ratio_yes\n",
    "            ratio_dict[word] = ratio_yes / ratio_no\n",
    "\n",
    "    # 저장\n",
    "    ratio_dict = sorted(ratio_dict.items(), key=operator.itemgetter(1))\n",
    "    ratio_dict.reverse()\n",
    "    print ratio_dict[:50]\n",
    "    f = open(util_folder + 'keywords2_' + after + '_' + before + '_ratio.pickle', 'w')\n",
    "    pickle.dump(ratio_dict, f)\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Automatically extract important keywords\n",
    "# Approach 2-2: 사용 예제\n",
    "\n",
    "for year in range(2010, 2017):\n",
    "    keyword2('{}-01-01'.format(year), '{}-01-01'.format(year + 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 346275\n",
      "50000 346275\n",
      "100000 346275\n",
      "150000 346275\n",
      "200000 346275\n",
      "250000 346275\n",
      "300000 346275\n"
     ]
    }
   ],
   "source": [
    "# 4. Automatically extract important keywords\n",
    "# Approach 3. LDA (topic model) 을 이용하여 중요한 토픽들을 찾아내고 각 단어의 상위 단어들을 키워드로 사용한다\n",
    "\n",
    "count = 0\n",
    "bigram_sentences_for_lda = []\n",
    "for sentence in sentences:\n",
    "    if count % 50000 == 0: print count, len(sentences)\n",
    "    bigram_sentence = bigram_transformer[sentence]\n",
    "    bigram_sentence = dictionary.doc2bow(bigram_sentence)\n",
    "    bigram_sentences_for_lda.append(bigram_sentence)\n",
    "    count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%time model = gensim.models.ldamodel.LdaModel(corpus = bigram_sentences_for_lda, id2word = dictionary)\n",
    "model.show_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
