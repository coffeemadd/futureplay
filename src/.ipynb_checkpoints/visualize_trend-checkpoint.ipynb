{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 주제/키워드가 주어졌을때 다음을 시각화 한다\n",
    "# 1. 구글 트렌드\n",
    "# 2. 투자\n",
    "# 3. 인수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import gensim\n",
    "import pickle\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load data\n",
    "data_folder = '../data/csv_export/'\n",
    "util_folder = '../util/'\n",
    "trend_folder = '../data/trends/'\n",
    "df_organizations = pd.read_csv(data_folder + 'organizations.csv'.format(data_folder), dtype={'first_funding_on': str, 'last_funding_on':str})\n",
    "df_description = pd.read_csv(data_folder + 'organization_descriptions.csv')\n",
    "df_funding_rounds = pd.read_csv(data_folder + 'funding_rounds.csv')\n",
    "df_funds = pd.read_csv(data_folder + 'funds.csv')\n",
    "df_investments = pd.read_csv(data_folder + 'investments.csv')\n",
    "df_acq = pd.read_csv(data_folder + 'acquisitions.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "주제가 주어졌을때 다음을 시각화 한다.\n",
    "1. 구글 트렌드\n",
    "2. 투자\n",
    "3. 인수\n",
    "\n",
    "keyword: google trend keyword (사전에 keyword.csv 이름의 파일을 trends.google.com 에서 다운 받아야 함)\n",
    "words: 회사 설명에서 다음과 같은 단어가 있으면 포함시킨다.\n",
    "expand: 기본 단어외의 관련 단어를 추가할 것인가?\n",
    "plot_all: 3가지가 모두 나온 하나의 그래프 외에, 개별 그래프 3가지를 따로 표시할 것인가?\n",
    "start_date: 시작 시점\n",
    "'''\n",
    "color1 = 'black'\n",
    "color2 = 'grey'\n",
    "color3 = '#80bfff'\n",
    "color4 = 'red'\n",
    "\n",
    "\n",
    "def visualize(keyword, words, expand = False, plot_all = False, start_date = '2004-01', cumulative = False):\n",
    "    fig = plt.figure()\n",
    "    condition = 'first_funding_on'\n",
    "\n",
    "    # 1. google web search trend data\n",
    "    df_google_trend = pd.read_csv(trend_folder + keyword + '.csv', header = 1)  \n",
    "    column1, column2 = df_google_trend.columns\n",
    "\n",
    "    df_google_trend['google_count'] = df_google_trend[column2].groupby(df_google_trend[column1].str[:7]).transform('mean')\n",
    "    df_google_trend['year-month'] = df_google_trend[column1].str[:7]\n",
    "    df_google_trend = df_google_trend.loc[:,['year-month', 'google_count']]\n",
    "    df_google_trend = df_google_trend.drop_duplicates()\n",
    "    df_google_trend.columns = ['year-month', 'google_count']\n",
    "    if plot_all:\n",
    "        df_google_trend.plot(kind = 'line', x = df_google_trend['year-month'], figsize = (30, 8))\n",
    "\n",
    "    # 2. google news trend data\n",
    "    df_google_news_trend = pd.read_csv(trend_folder + keyword + '_news.csv', header = 1)  \n",
    "    column1, column2 = df_google_news_trend.columns\n",
    "    df_google_news_trend['google_news_count'] = df_google_news_trend[column2].groupby(df_google_news_trend[column1].str[:7]).transform('mean')\n",
    "\n",
    "    df_google_news_trend['year-month'] = df_google_news_trend[column1].str[:7]\n",
    "    df_google_news_trend = df_google_news_trend.loc[:,['year-month', 'google_news_count']]\n",
    "    df_google_news_trend = df_google_news_trend.drop_duplicates()\n",
    "    df_google_news_trend.columns = ['year-month', 'google_news_count']\n",
    "    if plot_all:\n",
    "        df_google_news_trend.plot(kind = 'line', x = df_google_news_trend['year-month'], figsize = (30, 8))\n",
    "\n",
    "    # load required dataset\n",
    "    if 'word2company' not in globals():\n",
    "        print('loading word2company')\n",
    "        global word2company\n",
    "        word2company = pickle.load(open(util_folder + 'word2company.pickle', 'rb'))\n",
    "    if 'model' not in globals():\n",
    "        print('loading word2vec model')\n",
    "        global model\n",
    "        model = gensim.models.word2vec.Word2Vec.load(util_folder + 'word2vec')\n",
    "\n",
    "    # expand word set if necessary\n",
    "    # train 된 word2vec 을 사용하여 관련도가 높은 단어들을 포함한다\n",
    "    final_words = []\n",
    "    if type(words) == str:\n",
    "        words = [words]\n",
    "    for word in words:\n",
    "        if ' ' in word:\n",
    "            word = word.replace(' ', '_')\n",
    "        if expand:\n",
    "            if word not in model: continue\n",
    "            _words = model.most_similar(word)\n",
    "            _words = [str(_word) for _word, sim in _words]\n",
    "            final_words.extend(_words)\n",
    "        final_words.append(word)\n",
    "    final_words = list(set(final_words))\n",
    "\n",
    "    # choose companies that have relevant words\n",
    "    companies = []\n",
    "    for word in final_words:\n",
    "        _companies = word2company.get(word, [])\n",
    "        companies.extend(_companies)\n",
    "    companies = list(set(companies))\n",
    "\n",
    "    if not cumulative: # just to print once\n",
    "        print('Google Trend: {}\\n Companies with keywords:{}'.format(keyword, final_words))\n",
    "\n",
    "    # 회사를 시기 별로 정리한다\n",
    "    # 3. funding\n",
    "#     df_funding = df_funding_rounds[['company_uuid', 'funding_round_uuid', 'announced_on']]\n",
    "    df = pd.DataFrame(pd.concat([df_funding_rounds[df_funding_rounds['company_uuid'].isin(companies)]['announced_on']]))\n",
    "    df_companies = df_organizations[df_organizations['uuid'].isin(companies)]\n",
    "    df = pd.DataFrame()\n",
    "    df['date'] = df_companies[\"first_funding_on\"]\n",
    "    df = df[~df['date'].isnull()]\n",
    "    df['year-month'] = df['date'].str[:7]\n",
    "    \n",
    "    funding = df.groupby(df['year-month']).size().reset_index()\n",
    "    funding.columns = ['year-month', 'funding_count']\n",
    "    funding = funding[funding['year-month'] >= start_date]\n",
    "    if plot_all:\n",
    "        funding.plot(kind = 'bar', x = funding['year-month'], figsize = (30, 8))\n",
    "\n",
    "\n",
    "    df_merged = pd.merge(df_google_trend, funding, on = 'year-month', how = 'outer')\n",
    "    df_merged = df_merged.merge(df_google_news_trend, on = 'year-month', how = 'outer')\n",
    "\n",
    "    # 4. acquisition\n",
    "    df = df_acq[df_acq['acquiree_uuid'].isin(companies)]\n",
    "    if not cumulative:\n",
    "#         print(df[['acquiree_name', 'acquirer_name', 'acquired_on']].sort_values('acquired_on'))\n",
    "        to_print = df.sort_values('acquired_on')[['acquired_on', 'acquiree_name']]\n",
    "        to_print['acquiree_name'] = to_print['acquiree_name'].apply(lambda x: x[:15])\n",
    "        to_print = to_print.to_string(index = False)\n",
    "        print(to_print)\n",
    "#         print df.to_string(index=False)\n",
    "\n",
    "    df = df.loc[:,['acquired_on']]\n",
    "    df['year-month'] = df['acquired_on'].str[:7]\n",
    "    acq = df.groupby(df['year-month']).size().reset_index()\n",
    "    acq.columns = ['year-month', 'acq_count']\n",
    "    acq = acq[acq['year-month'] >= start_date]\n",
    "\n",
    "    if plot_all:\n",
    "        acq.plot(kind = 'bar', x = acq['year-month'], figsize = (30, 8))\n",
    "\n",
    "    df_merged = pd.merge(df_merged, acq, on = 'year-month', how = 'outer')\n",
    "    df_merged = df_merged.sort_values(['year-month'])    \n",
    "    df_merged['year'] = np.where(df_merged['year-month'].str[5:7] == '01', df_merged['year-month'].str[:4], '')\n",
    "\n",
    "    if cumulative:\n",
    "        df_merged['funding_count'] = df_merged['funding_count'].fillna(0)\n",
    "        df_merged['funding_count'] = df_merged['funding_count'].cumsum()\n",
    "\n",
    "        div_by = 100.0 / (df_merged['funding_count'].max() + 1)\n",
    "        df_merged['google_count'] /= div_by\n",
    "        df_merged['google_news_count'] /= div_by\n",
    "\n",
    "        df_merged['acq_count'] = df_merged['acq_count'].fillna(0)\n",
    "        df_merged['acq_count'] = df_merged['acq_count'].cumsum()\n",
    "        df_merged['acq_count'] /= ((df_merged['acq_count'].max()) / (df_merged['funding_count'].max() + 1))\n",
    "\n",
    "        df_merged[['year-month', 'google_count', 'google_news_count', 'funding_count', 'acq_count']].plot(x = df_merged['year'], linestyle = '-', color = [color1, color2, color3, color4], fontsize = 25, figsize = (30, 8)).legend(loc = 2, fontsize = 20, labels = ['google web search trend', 'google news trend', '# funding',  '# M&A',])\n",
    "\n",
    "\n",
    "    else:        \n",
    "\n",
    "        div_by = 100.0 / (df_merged['funding_count'].max() + 1)\n",
    "        df_merged['google_count'] /= div_by\n",
    "        df_merged['google_news_count'] /= div_by\n",
    "\n",
    "\n",
    "        ax = df_merged[['year-month', 'google_count', 'google_news_count']].plot(x = df_merged['year'], linestyle = '-', color = [color1, color2])\n",
    "        df_merged[['year-month', 'funding_count', 'acq_count']].plot(x = df_merged['year'], kind = 'bar', rot = 0, ax = ax, fontsize = 25, figsize = (30, 8), color = [color3, color4]).legend(loc = 2, fontsize = 20, labels = ['google web search trend', 'google news trend', '# funding', '# M&A'])\n",
    "\n",
    "def visualize_all(keyword, words, expand = False, plot_all = False, start_date = '2004-01'):\n",
    "    visualize(keyword, words, expand = expand, plot_all = plot_all, start_date = start_date, cumulative = False)\n",
    "    visualize(keyword, words, expand = expand, plot_all = plot_all, start_date = start_date, cumulative = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading word2company\n",
      "loading word2vec model\n",
      "Google Trend: augmented_reality\n",
      " Companies with keywords:['augmented_reality']\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'year-month'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m~/Projects/kaggle_instacart/venv/lib/python3.4/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2441\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2442\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2443\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc (pandas/_libs/index.c:5280)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc (pandas/_libs/index.c:5126)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item (pandas/_libs/hashtable.c:20523)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item (pandas/_libs/hashtable.c:20477)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'year-month'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-f14e5c42adbf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mvisualize_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'augmented_reality'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'augmented_reality'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpand\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplot_all\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-6-3b426df35c05>\u001b[0m in \u001b[0;36mvisualize_all\u001b[0;34m(keyword, words, expand, plot_all, start_date)\u001b[0m\n\u001b[1;32m    150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mvisualize_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyword\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwords\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpand\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplot_all\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_date\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'2004-01'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 152\u001b[0;31m     \u001b[0mvisualize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyword\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwords\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpand\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexpand\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplot_all\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplot_all\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_date\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstart_date\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcumulative\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    153\u001b[0m     \u001b[0mvisualize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyword\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwords\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpand\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexpand\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplot_all\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplot_all\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_date\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstart_date\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcumulative\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-3b426df35c05>\u001b[0m in \u001b[0;36mvisualize\u001b[0;34m(keyword, words, expand, plot_all, start_date, cumulative)\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;31m#     df['year-month'] = df['date'].str[:7]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m     \u001b[0mfunding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'year-month'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m     \u001b[0mfunding\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'year-month'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'funding_count'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0mfunding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunding\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfunding\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'year-month'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mstart_date\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Projects/kaggle_instacart/venv/lib/python3.4/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1962\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1963\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1964\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1965\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1966\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_getitem_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Projects/kaggle_instacart/venv/lib/python3.4/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_getitem_column\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1969\u001b[0m         \u001b[0;31m# get column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1970\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_unique\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1971\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_item_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1972\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1973\u001b[0m         \u001b[0;31m# duplicate columns & possible reduce dimensionality\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Projects/kaggle_instacart/venv/lib/python3.4/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_get_item_cache\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m   1643\u001b[0m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1644\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mres\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1645\u001b[0;31m             \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1646\u001b[0m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_box_item_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1647\u001b[0m             \u001b[0mcache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Projects/kaggle_instacart/venv/lib/python3.4/site-packages/pandas/core/internals.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, item, fastpath)\u001b[0m\n\u001b[1;32m   3588\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3589\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misnull\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3590\u001b[0;31m                 \u001b[0mloc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3591\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3592\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0misnull\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Projects/kaggle_instacart/venv/lib/python3.4/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2442\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2443\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2444\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2445\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2446\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc (pandas/_libs/index.c:5280)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc (pandas/_libs/index.c:5126)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item (pandas/_libs/hashtable.c:20523)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item (pandas/_libs/hashtable.c:20477)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'year-month'"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fe38cff74a8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "visualize_all('augmented_reality', ['augmented_reality'], expand = False, plot_all = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_all('wearable', ['wearable', 'wearables', 'smartwatch', 'smart_glasses', 'wearable_device', 'wrist_worn', 'wearable_sensor', 'wearable_devices', 'wearable', 'wearable_tech', 'wearable_technology'], plot_all = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "visualize_all('iot', 'iot', expand = False, plot_all = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_all('bitcoin', 'bitcoin', expand = True, plot_all = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "visualize_all('blockchain', 'blockchain', expand = False, plot_all = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_all('deep_learning', 'deep learning', expand = False, plot_all = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "visualize_all('drone', 'drone', expand = True, plot_all = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "visualize_all('social_media', 'social_media', expand = False, plot_all = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_all('self_driving_car', ['self driving', 'autonomous driving', 'driverless', 'autonomous vehicle'], expand = False, plot_all = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_all('neuroscience', ['neuroscience'], expand = False, plot_all = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_all('mobile_health_care', ['mobile health', 'mobile healthcare'], expand = True, plot_all = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_all('social_robot', 'social robot', expand = True, plot_all = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_all('lidar', 'lidar', expand = False, plot_all = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize_all('chatbot', ['chatbot', 'conversational', 'chat bot', 'ibm watson', 'siri'], expand = False, plot_all = False)\n",
    "visualize_all('chatbot', ['chatbot', 'chat bot', 'ibm watson', 'siri'], expand = False, plot_all = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_all('fintech', 'fintech', expand = False, plot_all = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_all('3d_printing', '3d printing', expand = True, plot_all = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_all('quantum_computing', 'quantum_computing', expand = False, plot_all = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
